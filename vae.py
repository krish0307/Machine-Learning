# -*- coding: utf-8 -*-
"""vae.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WZsFDdPbs-ILXwV0T_jDqyXB5YZnghOK
"""

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
import torch
# %load_ext tensorboard
import torch.utils.tensorboard as tb
import tempfile
log_dir=tempfile.mkdtemp()
# %tensorboard --logdir {log_dir} --reload_interval 1

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.utils import save_image, make_grid
from torch.utils.tensorboard import SummaryWriter
import torch.nn.functional as F


from sklearn.manifold import TSNE
import numpy as np
import matplotlib.pyplot as plt

def interpolate_latent_vectors_and_visualize(vae, data_loader, class1, class2, device,steps=10):
    # Compute the mean latent vectors for the chosen classes
    mu_class1, mu_class2 = [], []
    for data, labels in data_loader:
        data = data.to(device)
        mu, _ = vae.encode(data)
        mu_class1.extend(mu[labels == class1].detach().cpu().numpy())
        mu_class2.extend(mu[labels == class2].detach().cpu().numpy())

    mu_class1_mean = torch.tensor(np.mean(mu_class1, axis=0)).to(device)
    mu_class2_mean = torch.tensor(np.mean(mu_class2, axis=0)).to(device)

    # Interpolate between the mean latent vectors
    interpolated_images = []
    for alpha in np.linspace(0, 1, steps):
        z_interp = alpha * mu_class1_mean + (1 - alpha) * mu_class2_mean
        interp_image = vae.decode(z_interp).view(28, 28).detach().cpu().numpy()
        interpolated_images.append(interp_image)

    # Visualize the interpolated images
    plt.figure(figsize=(15, 2))
    for i, img in enumerate(interpolated_images):
        plt.subplot(1, len(interpolated_images), i + 1)
        plt.imshow(img, cmap='gray')
        plt.axis('off')

    plt.suptitle(f'Interpolation between class {class1} and class {class2}', fontsize=16)
    plt.show()


class ImprovedVAE(nn.Module):
    def __init__(self, latent_dim=2):
        super(ImprovedVAE, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Flatten(),
            nn.Linear(64 * 7 * 7, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim*2)
        )

        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64 * 7 * 7),
            nn.ReLU(),
            nn.Unflatten(1, (64, 7, 7)),
            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, kernel_size=2, stride=2),
            nn.Sigmoid()
        )

    def encode(self, x):
        h = self.encoder(x)
        mu, logvar = h.chunk(2, dim=1)
        return mu, logvar

    def decode(self, z):
        return self.decoder(z)


    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar

def vae_loss(recon_x, x, mu, logvar):
    bce = nn.functional.binary_cross_entropy(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')
    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return bce + kld


def train(epoch, model, dataloader, device, optimizer, writer):
    model.train()
    train_loss = 0
    for batch_idx, (data, _) in enumerate(dataloader):
        data = data.to(device)
        # data = data.view(-1, 784) ## For linear neural net
        optimizer.zero_grad()
        recon_batch, mu, logvar = model(data)
        loss = vae_loss(recon_batch, data, mu, logvar)
        loss.backward()
        train_loss += loss.item()
        optimizer.step()

        # Log mean and log variance of latent space to TensorBoard
        writer.add_histogram('mu', mu, epoch)
        writer.add_histogram('logvar', logvar, epoch)
       
        reconstruction_error = F.binary_cross_entropy(recon_batch.view(-1, 784), data.view(-1, 784), reduction='mean')
        writer.add_scalar('Reconstruction_error', reconstruction_error.item(), epoch)

        if batch_idx % 100 == 0:
            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(dataloader.dataset)}] Loss: {loss.item() / len(data)}')

    average_loss = train_loss / len(dataloader.dataset)
    writer.add_scalar('training_loss', average_loss, epoch)
    print(f'====> Epoch: {epoch} Average loss: {average_loss}')


epochs = 50
batch_size = 100
latent_dim = 4
learning_rate = 0.003
def main():
    # Hyperparameters
    

    # Set device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load MNIST dataset
    transform = transforms.Compose([transforms.ToTensor()])
    dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # Initialize the VAE model
    model = ImprovedVAE(latent_dim=latent_dim).to(device)
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # TensorBoard writer
    writer = SummaryWriter(log_dir)

    os.makedirs("checkpoints", exist_ok=True)
    os.makedirs("results", exist_ok=True)
    # Start training
    for epoch in range(1, epochs + 1):
        train(epoch, model, dataloader, device, optimizer, writer)

        # Save images during training
        with torch.no_grad():
            sample = torch.randn(64, latent_dim).to(device)
            sample = model.decoder(sample).cpu()
            save_image(sample.view(64, 1, 28, 28), f'results/sample_{epoch}.png')
            grid = make_grid(sample.view(64, 1, 28, 28), nrow=8)
            writer.add_image('generated_images', grid, epoch)

        # Save the model checkpoint
        torch.save(model.state_dict(), f'checkpoints/vae_epoch_{epoch}.pth')

    # Save the final model
    torch.save(model.state_dict(), 'checkpoints/vae_final.pth')
    
    # Close the TensorBoard writer
    writer.close()

if __name__ == '__main__':
    main()

# Set the device
from mpl_toolkits.mplot3d import Axes3D

def visualize_latent_space3D(model, dataloader, device, n_samples=500, latent_dim=3):
    model.eval()
    zs, ys = [], []
    with torch.no_grad():
        for i, (x, y) in enumerate(dataloader):
            x = x.to(device)
            # x=x.view(-1,784)
            mu, logvar = model.encode(x)
            z = model.reparameterize(mu, logvar)
            z = z.cpu().numpy()
            zs.append(z)
            ys.append(y.numpy())
            if (i + 1) * len(x) >= n_samples:
                break

    zs = np.concatenate(zs, axis=0)
    ys = np.concatenate(ys, axis=0)

    tsne = TSNE(n_components=3)
    zs_3d = tsne.fit_transform(zs)

    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(111, projection='3d')
    for i in range(10):
        indices = ys == i
        ax.scatter(zs_3d[indices, 0], zs_3d[indices, 1], zs_3d[indices, 2], label=str(i), alpha=0.7)
    plt.legend()
    plt.title("Latent space visualization using 3D t-SNE")
    plt.savefig('latent_space_tsne_3d.png')
    plt.show()

def visualize_latent_space(model, dataloader, device, n_samples=500, latent_dim=2):
    model.eval()
    zs, ys = [], []
    with torch.no_grad():
        for i, (x, y) in enumerate(dataloader):
            x = x.to(device)
            # x=x.view(-1,784)
            mu, logvar = model.encode(x)
            z = model.reparameterize(mu, logvar)
            z = z.cpu().numpy()
            zs.append(z)
            ys.append(y.numpy())
            if (i + 1) * len(x) >= n_samples:
                break

    zs = np.concatenate(zs, axis=0)
    ys = np.concatenate(ys, axis=0)

    tsne = TSNE(n_components=2)
    zs_2d = tsne.fit_transform(zs)

    plt.figure(figsize=(10, 10))
    for i in range(10):
        indices = ys == i
        plt.scatter(zs_2d[indices, 0], zs_2d[indices, 1], label=str(i), alpha=0.7)
    plt.legend()
    plt.title("Latent space visualization using t-SNE")
    plt.savefig('latent_space_tsne.png')
    plt.show()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Instantiate the Generator and Discriminator models
vae = ImprovedVAE(latent_dim=latent_dim).to(device)

# Load the saved model weights
vae_weights_path = "checkpoints/vae_final.pth"

vae.load_state_dict(torch.load(vae_weights_path, map_location=device))

transform = transforms.Compose([transforms.ToTensor()])
dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
dataloader = DataLoader(dataset, batch_size=100, shuffle=True)
visualize_latent_space(vae, dataloader, device, n_samples=1000, latent_dim=latent_dim)
visualize_latent_space3D(vae, dataloader, device, n_samples=1000,latent_dim=latent_dim)

optimizer = optim.Adam(vae.parameters(), lr=learning_rate)

# TensorBoard writer
writer = SummaryWriter(log_dir)

os.makedirs("checkpoints", exist_ok=True)
os.makedirs("results", exist_ok=True)
# Start training
for epoch in range(1, epochs + 1):
    train(epoch, vae, dataloader, device, optimizer, writer)

    # Save images during training
    with torch.no_grad():
        sample = torch.randn(64, latent_dim).to(device)
        sample = vae.decoder(sample).cpu()
        save_image(sample.view(64, 1, 28, 28), f'results/sample_{epoch}.png')
        grid = make_grid(sample.view(64, 1, 28, 28), nrow=8)
        writer.add_image('generated_images', grid, epoch)

    # Save the model checkpoint
    torch.save(vae.state_dict(), f'checkpoints/vae_epoch_{epoch}.pth')

# Save the final model
torch.save(vae.state_dict(), 'checkpoints/vae_final.pth')

# Close the TensorBoard writer
writer.close()